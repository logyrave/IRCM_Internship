import requests
import aiohttp
import asyncio
import pandas as pd
import re
import json 

def extract_mar_id(text):
    match = re.search(r"MAR0\d+", str(text))
    return match.group(0) if match else None

def extract_hmr_id(text):
    match = re.search(r"HMR_\d+", str(text))
    return match.group(0) if match else None


'''
Get BiGG gene ID from HMR reaction ID following the process: 
1. Extract MAR ID from HMR ID via simple regex
2. Request MetabolicAtlas API to get BiGG ID from MAR ID

async def used in order to parallelize requests because the API can take some time to respond
'''
API_URL = "https://metabolicatlas.org/api/v2/reactions/{}?model=HumanGem"

async def fetch_bigg(session, mar_id):
    """Effectue une requ√™te asynchrone pour r√©cup√©rer l'ID BiGG d'un MAR_ID."""
    
    url = API_URL.format(mar_id)
    try:
        async with session.get(url, headers={"accept": "application/json"}, ssl=False, timeout=10) as response:
            if response.status == 200:
                data = await response.json()
                print(f"‚úÖ R√©ponse API pour {mar_id}: {json.dumps(data, indent=2)}")  # DEBUG API

                # V√©rifier si BiGG existe dans la r√©ponse JSON
                bigg_entry = data.get("externalDbs", {}).get("BiGG", [])
                return mar_id, bigg_entry[0]["id"] if bigg_entry else None
            else:
                print(f"‚ö†Ô∏è Erreur HTTP {response.status} pour {mar_id}")
                return mar_id, None
    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration de {mar_id}: {e}")
        return mar_id, None

async def fetch_all_bigg(mar_ids):
    """G√®re plusieurs requ√™tes asynchrones pour r√©cup√©rer les IDs BiGG en batch."""
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_bigg(session, mar_id) for mar_id in mar_ids]
        results = await asyncio.gather(*tasks)

        # Afficher les r√©sultats pour voir s'ils sont bien extraits
        print("\n‚úÖ R√©sum√© des r√©sultats BiGG r√©cup√©r√©s :")
        for mar, bigg in results[:10]:  # Affiche les 10 premiers r√©sultats
            print(f"MAR_ID: {mar} -> BiGG_ID: {bigg}")

        return dict(results)

def extract_hmr_to_mar(text):
    """G√®re les cas o√π Metadata contient :
    1. Un ID MAR0xxxx ‚Üí on le retourne directement.
    2. Un ID HMR_xxxx ‚Üí on le convertit en MAR0xxxx.
    """
    text = str(text).strip()

    # Cas o√π Metadata contient d√©j√† MAR0xxxx
    match_mar = re.search(r"(MAR0\d+)", text)
    if match_mar:
        return match_mar.group(1)

    # Cas o√π Metadata contient HMR_xxxx ‚Üí conversion en MAR0xxxx
    match_hmr = re.search(r"HMR_(\d+)", text)
    if match_hmr:
        return f"MAR0{match_hmr.group(1)}"  # Conversion en MAR0xxxx

    # Si aucun des deux cas ne correspond, retourne None
    return None

def batch_fetch_bigg(input_file, output_file):
    """Lecture des donn√©es, conversion HMR -> MAR, et r√©cup√©ration des BiGG_ID en batch."""
    df = pd.read_csv(input_file, low_memory=False)

    # üîπ V√©rifier si la premi√®re ligne est une en-t√™te incorrecte
    if "Metadata" in df.columns:
        print("‚ö†Ô∏è En-t√™te d√©tect√©e, elle sera ignor√©e.")
        df = df.iloc[1:].reset_index(drop=True)

    df["MAR_ID"] = df["Metadata"].apply(extract_hmr_to_mar)
    
    mar_ids = df["MAR_ID"].dropna().unique().tolist()
    bigg_mapping = asyncio.run(fetch_all_bigg(mar_ids))

    df["BiGG_ID"] = df["MAR_ID"].map(bigg_mapping)
    df.to_csv(output_file, index=False)
    print(df[["Metadata", "MAR_ID"]].drop_duplicates().head())  # V√©rifie conversion
    print("‚úÖ R√©cup√©ration des BiGG_ID termin√©e.")
    
    
def process_metadata_column(df):
    """S√©pare la colonne 'Metadata' en 'Batch' et 'Cell_Type' et supprime MAR_ID."""
    df[["Batch", "Cell_Type"]] = df["Metadata"].str.extract(r"(batch_\d+)\.celltype (\d+)")
    df.drop(columns=["Metadata"], inplace=True)  
    return df

def process_raw_Metaflux_output(input_file):
    df = pd.read_csv(input_file, header=None, low_memory=False)

    # üîπ V√©rifier qu'on a bien des colonnes num√©riques
    if df.shape[1] < 2:
        raise ValueError("Le fichier d'entr√©e doit contenir au moins 2 colonnes (Metadata + valeurs).")

    df.columns = ["Metadata"] + [f"V{i}" for i in range(1, df.shape[1])]

    df.iloc[:, 1:] = df.iloc[:, 1:].apply(pd.to_numeric, errors="coerce")

    df["Metadata"] = df["Metadata"].apply(lambda x: re.sub(r"HMR_(\d+)", r"MAR0\1", str(x)))

    df["Value"] = df.iloc[:, 1:].mean(axis=1)

    # üîπ Supprimer les NaN √©ventuels dans Metadata
    df.dropna(subset=["Metadata"], inplace=True)

    df_final = df[["Metadata", "Value"]].copy()
    print(f"\n‚úÖ Transformation r√©ussie ! Format final :\n{df_final.head()}\n")
    return df_final

